# Persona 
*A local, private AI-powered interview coach.*  

---

Jump to [Overview](#overview)  
Jump to [Why GPT-OSS:20B](#why-gpt-oss20b)  
Jump to [Project Structure](#project-structure)  
Jump to [Requirements](#requirements)  
Jump to [Install dependencies](#install-dependencies)  
Jump to [Important Ollama Setup](#ollama-setup)  
Jump to [Usage](#usage)  
Jump to [Tech Stack](#tech-stack)  
Jump to [License](#license)  
Jump to [Author](#author)

---

## Overview  
**Persona** is a completely **local AI interview coach** that helps candidates practice for interviews across any domain.  

Unlike online tools, Persona ensures **100% privacy** by running fully on your machine. It adapts to your skills, the employerâ€™s requirements, and provides **real-time verbal interviews** powered by the **GPT-OSS:20B** model.  

Persona also uses **Mediapipe + OpenCV** to analyze your **posture and body language** during the session, giving instant feedback and generating detailed reports with:  
- ğŸ“Š Confidence scoring  
- ğŸ—£ï¸ Answer quality  
- ğŸŒ English proficiency  
- ğŸ§ Posture tracking  
- ğŸ“‘ Recruiter insights  

Built with **Flet**, Persona delivers a **sleek, minimalist GUI** optimized for performance so that system resources are prioritized for the model itself.  

---

## Why GPT-OSS:20B?  
Persona is powered by **GPT-OSS:20B**, chosen specifically for its unique advantages:  

- ğŸ“ **128K context window** â†’ handles long interviews seamlessly.  
- âš¡ **MXFP4 quantization** â†’ reduces memory + compute requirements while maintaining high accuracy.  
- ğŸ”€ **Mixture-of-Experts architecture** â†’ enables blazing-fast inference speeds, even on CPU. 

This combination makes Persona **fast, private, and reliable** â€” unlike most online interview tools.  

---


## Screenshots  

![Landing Page](Persona%20demo/Screenshot%202025-09-02%20115239.png)  
*Minimalist landing page with "Get Started" flow.*  

![Interview Session](Persona%20demo/Screenshot%202025-09-09%20154458.png)
*Live posture tracking and verbal interview interface.*  

![Analytics Report](Persona%20demo/Screenshot%202025-09-09%20154348.png)  
*Line graph showing confidence, answer quality, proficiency, and posture.*  

---

## Project Structure  

```bash
Persona/              
â”œâ”€â”€ 08-09, 19-34.json       # Session/experiment logs
â”œâ”€â”€ 08-09, 19-44.json
â”œâ”€â”€ 08-09, 20-48.json
â”œâ”€â”€ 08-09, 22-34.json
â”‚
â”œâ”€â”€ LICENSE                 # License file
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚
â”œâ”€â”€ Sylphie_voice.py        # Voice synthesis and processing (Piper TTS)
â”œâ”€â”€ eye_detection.py        # Eye detection / vision-based module
â”œâ”€â”€ hugginface_inference.py # Hugging Face inference integration
â”œâ”€â”€ main.py                 # Main entry point of the project
â”œâ”€â”€ ollama_gpt.py           # Ollama GPT integration module (GPT-OSS:20B)
â”œâ”€â”€ python_pdf_docx.py      # PDF/Docx processing module (CV parsing)
â”‚
â”œâ”€â”€ assets/                 
â”‚   â”œâ”€â”€ fonts/              # Montserrat-Regular.ttf 
â”‚   â””â”€â”€ images/             # App icons, graphics, screenshots
â”‚
â”œâ”€â”€ piper_models/           # Voice models (Piper TTS, default voice included as hfc_female)
â””â”€â”€ .gitignore
```

## Requirements

- Python 3.12.7
- Ollama (for GPT-OSS:20B local inference)
- CUDA-compatible GPU (optional, for faster inference)
- Works on Linux / macOS / Windows
- At least 16gb of system RAM

## Install dependencies

```
git clone https://github.com/<your-username>/persona.git
cd persona
python3.12 -m venv venv
source venv/bin/activate   # (or venv\Scripts\activate on Windows)
pip install -r requirements.txt
```
## Ollama Setup

> ğŸ”´ Note: Persona relies on GPT-OSS:20B running locally via Ollama. Make sure you have the correct Ollama version installed and running.

Install Ollama â†’ [Download here](https://ollama.com/download)

Verify Ollama version

```
ollama --version
```
(Recommended: latest stable version)

Pull GPT-OSS:20B model
```
ollama pull gpt-oss:20b
```

Start Ollama service (must run in the background)
```
ollama run gpt-oss:20b
```

## Usage

Start the app
```
python main.py
```

On launch:
- Click Get Started.

- Upload your CV (PDF/DOCX) or skip for demo.

- Choose your field of work and role.

- Enter details about yourself and what the employer is looking for.

- Persona begins the mock interview:

- Verbal Q/A in real time with GPT-OSS:20B.

- Faster-Whisper handles speech-to-text.

- Posture analysis runs with Mediapipe + OpenCV.

> After interview:

Get detailed analytics with graphs and recruiter-style notes.

## Tech Stack

- LLM: GPT-OSS:20B (via Ollama)
- Runner: Ollama (local model hosting)
- STT: Faster-Whisper (small model, GPU-accelerated if available)
- TTS: Piper (default female voice hfc_female)
- GUI: Flet
- Vision: Mediapipe + OpenCV (posture, eye detection)
- Python: 3.12.7

## License 
Apache 2.0

## Author
Developed by Anshul.





